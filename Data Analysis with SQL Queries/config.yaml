llm:
  crewai_agent_model: "groq/llama-3.3-70b-versatile"
  langgraph_agent_model: "llama-3.3-70b-versatile"
  rating_model: "llama-3.2-90b-vision-preview"
  temperature: 0.1
  max_tokens: 1000

model:
    name: "llama3-70b-8192"
    temperature: 0.01
    max_tokens: 1000
    # Rate limiting values
    max_calls: 4
    pause_time: 30
    token_limit: 90000
    # Retry values
    stop_after_attempt: 3
    wait_multiplier: 60
    wait_min: 180
    wait_max: 300


benchmarks:
  iterations: 3  # Number of times to run the complete test
  total_questions: 5
  metrics:
    - api_calls
    - latency 

csv:
  crewai_filename: "crewai_benchmark_results.csv"
  langgraph_filename: "langgraph_benchmark_results.csv"
  autogen_filename: "autogen_benchmark_results.csv"
  columns: 
    - "Question"
    - "Query executed"
    - "Query result"
    - "Answer"

data:
  paths:
    input_dir: "data"
    env: "~/src/python/.env"
    metrics: "metrics"

logging:
  file: "logs/amazon_query.log"
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

results:
  directory: "results"