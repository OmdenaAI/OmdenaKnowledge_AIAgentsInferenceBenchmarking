llm:
  crewai_agent_model: "groq/llama-3.3-70b-versatile"
  langgraph_agent_model: "llama-3.3-70b-versatile"
  rating_model: "llama-3.2-90b-vision-preview"
  temperature: 0.1
  max_tokens: 1000

tiktoken_encoder: "cl100k_base" 

prompts:
  paragraph_rating:
    system:  |
      You are an AI assistant that rates paragraphs on a scale of 1-10 based on:
      1. Clarity and coherence
      2. Relevance to the topic
      3. Engagement and fluency.
      Respond with only a single number between 1 and 10.
    user: "{paragraph}"
  
  agent:
    role: "Content Writer"
    goal: "Generate a short descriptive paragraph based on a single input keyword."
    backstory: "A skilled AI writer trained to craft engaging and meaningful content."
  
  task:
    description: "The agent will generate a short, descriptive paragraph based on {keyword}. It should ensure clarity, coherence, and relevance while maintaining an engaging tone."
    expected_output: |
      A well-structured, concise, and descriptive paragraph (50-100 words).
      The paragraph should be grammatically correct and contextually relevant to the keyword.
      The style should be engaging and adaptable to different contexts if required.

benchmark:
  test_queries:
    - "Rainforest"
    - "Desert"
    - "Robotics"
    - "Blockchain"
    - "Tennis"
    - "Golf"
    - "Coffee"
    - "Friendship"
    - "Venice"
    - "Tokyo"
    - "Galaxy"
    - "DNA"
    - "Painting"
    - "Sculpture"
    
   

csv:
  crewai_filename: "crewai_benchmark_results.csv"
  langgraph_filename: "langgraph_benchmark_results.csv"
  autogen_filename: "autogen_benchmark_results.csv"
  columns: 
    - "Keyword"
    - "Latency (seconds)"
    - "Generated Paragraph"
    - "Response Ratings"
    - "Peak Memory"
    - "Memory Delta"
    - "Input Tokens"
    - "Output Tokens"
    - "Total Tokens"
  summary:
    keyword: "SUMMARY"
    latency: "Total Keywords Processed: {total_keywords}"
    generated_paragraph: "Total Time Taken: {total_time_taken:.4f} sec"
    response_ratings: "Throughput: {throughput:.4f} keywords/sec"
    tokens_used: "Total Tokens Used: {total_tokens}"
    peak_memory: ""
    memory_delta: ""